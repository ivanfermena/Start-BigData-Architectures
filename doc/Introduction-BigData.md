## Introduccion al BigData

### Que es el Big Data?
Es una convergencia de enormes cantidades de datos estructurados (Bases de datos relacionales) y no estructurados (twitter, blogs, webs, sensores...)

Se generan aproximadamente 22574 GB de datos al minuto.

Todos estos datos lo que se pretende es extraerlo y procesarlos en un entorno Big Data, para que se produzca un estudio mas exaustivo mas adelante o en directo (streaming)

 ### Las tres Vs

![Las tres Vs](https://www.whishworks.com/hs-fs/hubfs/Blog/The-3Vs-of-big-data.png?t=1532764549415&width=618&name=The-3Vs-of-big-data.png)


- **Volumen** -> Gran cantidad de datos, hablando de TeraBytes o PetaBytes.
- **Variedad** -> Muchos tipos de datos diferentes: estructurados, no-estructurados o incluso semi-estructurados.
- **Velocidad** -> Con el procesamiento en tres tipos: Batch (Posterior procesamiento), streaming (procesamiento en directo) y hibridos (Ambas opciones).

Aunque expertos dictan que se pueden insertar mas Vs a esa lista como : 
- **Veracidad** -> Hay que estudiar si los datos que se obtienen son correctos para un estudios o pueden perjudicar el estudio debido a un contexto diferente. Por ejemplo: twitter.
- **Valor** -> Hay que tener en cuenta cuanto se puede obtener con esos datos, en la era de la informacion la obtencion de datos valiosos pueden ser un gran beneficio para un estudio.

![Cluster](http://2.bp.blogspot.com/-e0RNCaChLJ8/VozIUTvw-kI/AAAAAAAADTg/ruruyVD45vw/s1600/add_decompose_datanode.jpg)

Como no somos capaces de procesar tantas cantidades de datos lo que se hace es usar el procesamiento distribuido, es decir, en muchos ordenadores en forma de cluster para poder acelerar ese procesamiento. Para eso usaremos Hadoop o tegnologias basadas en esta.
